{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating performance of regression models\n",
    "This notebook explains how to use CNTK metric functions to validate the performance of a regression model.\n",
    "We're using the [car MPG dataset](https://archive.ics.uci.edu/ml/datasets/Auto+MPG) from the UCI dataset library. This dataset is perfect for demonstrating how to build a regression model using CNTK. \n",
    "\n",
    "In the dataset, you'll find 9 columns:\n",
    "\n",
    "1. mpg: continuous \n",
    "2. cylinders: multi-valued discrete \n",
    "3. displacement: continuous \n",
    "4. horsepower: continuous \n",
    "5. weight: continuous \n",
    "6. acceleration: continuous \n",
    "7. model year: multi-valued discrete \n",
    "8. origin: multi-valued discrete \n",
    "9. car name: string (unique for each instance)\n",
    "\n",
    "All columns in the dataset contain numeric values except for the origin column which is a categorical value.\n",
    "We'll strip the `car name` column as it cannot be used in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "The model we're using features two hidden layers. Each with 64 neurons with a ReLU (Rectified Linear Unit) activation function. The output is a single neuron without an activation function. This is necessary to turn this neural network into a regression model.\n",
    "\n",
    "We're using the 8 input features and the miles per gallon as target for our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk import default_options, input_variable\n",
    "from cntk.layers import Dense, Sequential\n",
    "from cntk.ops import relu\n",
    "\n",
    "with default_options(activation=relu):\n",
    "    model = Sequential([\n",
    "        Dense(64),\n",
    "        Dense(64),\n",
    "        Dense(1,activation=None)\n",
    "    ])\n",
    "    \n",
    "features = input_variable(X.shape[1])\n",
    "target = input_variable(1)\n",
    "\n",
    "z = model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "In this section we'll first preprocess the data so that it is compatible for use with our neural network.\n",
    "We need to load the data and then clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_csv('auto-mpg.csv', na_values=['?'])\n",
    "df_cars = df_cars.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origin column contains three possible values, as is shown in the dictionary below. To use the origin in the neural network we need to split it into three separate columns. For this we'll first replace the numeric values with a string value. After we've done that, we ask pandas to generate dummy columns. This creates three columns: usa, europa, and japan. For each sample in the dataset, one of these columns will contain a value of 1 and the rest will contain a value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_mapping = {\n",
    "    1: 'usa',\n",
    "    2: 'europe',\n",
    "    3: 'japan'\n",
    "}\n",
    "\n",
    "df_cars.replace({'origin': origin_mapping}, inplace=True)\n",
    "\n",
    "categorical_origin = pd.get_dummies(df_cars['origin'], prefix='origin')\n",
    "\n",
    "df_cars = pd.concat([df_cars, categorical_origin], axis=1)\n",
    "df_cars = df_cars.drop(columns=['origin', 'car name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result of this operation is the following dataset. It contains 9 columns. Of these columns the `mpg` column is used as the target output. The rest is used as a feature for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cars.drop(columns=['mpg']).values.astype(np.float32)\n",
    "y = df_cars.iloc[:,0].values.reshape(-1,1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has some really extreme values that do not sit well with our neural network. When you run the training process without scaling the inputs you end up with exploding gradients in your neural network. So we apply standard scaling which scales the values to +1 and -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good dataset, we need to create a hold-out set to ensure that we validate the performance on data that we haven't used for training. This is important as this will tell us how the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network\n",
    "Now that we have a neural network, let's train it using the training set.\n",
    "We're using a squared error loss function which is a regular loss that you will find in almost any regression model. We'll train the model using a SGD learner, which is the most basic learner around for CNTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.001\n",
      "      516        516          0          0            16\n",
      "      587        622          0          0            48\n",
      "      585        584          0          0           112\n",
      "      490        406          0          0           240\n",
      "     76.3       76.3          0          0            16\n",
      "     60.5       52.6          0          0            48\n",
      "     49.2       40.7          0          0           112\n",
      "     34.9       22.5          0          0           240\n",
      "       14         14          0          0            16\n",
      "     15.9       16.8          0          0            48\n",
      "     16.7       17.4          0          0           112\n",
      "     14.8         13          0          0           240\n",
      "       10         10          0          0            16\n",
      "     11.4       12.1          0          0            48\n",
      "     13.1       14.5          0          0           112\n",
      "     11.7       10.5          0          0           240\n",
      "      7.9        7.9          0          0            16\n",
      "     9.36       10.1          0          0            48\n",
      "     11.3       12.7          0          0           112\n",
      "     10.2       9.31          0          0           240\n",
      "     6.62       6.62          0          0            16\n",
      "     8.11       8.85          0          0            48\n",
      "     10.1       11.6          0          0           112\n",
      "     9.31       8.61          0          0           240\n",
      "     5.89       5.89          0          0            16\n",
      "     7.31       8.02          0          0            48\n",
      "     9.39         11          0          0           112\n",
      "     8.74       8.18          0          0           240\n",
      "     5.39       5.39          0          0            16\n",
      "     6.75       7.42          0          0            48\n",
      "     8.88       10.5          0          0           112\n",
      "     8.36        7.9          0          0           240\n",
      "     5.08       5.08          0          0            16\n",
      "     6.37       7.02          0          0            48\n",
      "     8.52       10.1          0          0           112\n",
      "     8.09        7.7          0          0           240\n",
      "     4.86       4.86          0          0            16\n",
      "     6.09       6.71          0          0            48\n",
      "     8.24       9.85          0          0           112\n",
      "     7.88       7.56          0          0           240\n"
     ]
    }
   ],
   "source": [
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.losses import squared_error\n",
    "from cntk.learners import sgd\n",
    "\n",
    "loss = squared_error(z, target)\n",
    "learner = sgd(z.parameters, 0.001)\n",
    "\n",
    "progress_printer = ProgressPrinter(0)\n",
    "\n",
    "train_summary = loss.train((X_train,y_train), \n",
    "                           parameter_learners=[learner], \n",
    "                           callbacks=[progress_printer],\n",
    "                           minibatch_size=16,\n",
    "                           max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the training session is looking promising, you can see that the loss is going down quite nicely. It's not perfect, but not bad for a first attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performance\n",
    "In order to measure the performance of our model we're going to use the mean absolute error metric.\n",
    "This metric gives us a good idea of just how much we're off predicting the miles per gallon.\n",
    "\n",
    "CNTK doesn't include a mean absolute error function, but you can easily create it yourself using the standard CNTK ops.\n",
    "\n",
    "We're using the test method on the metric to determine how well our model is doing. This is different from the classification model where we had to do quite a bit more to measure the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk \n",
    "\n",
    "def absolute_error(z, l):\n",
    "    return cntk.ops.reduce_mean(cntk.ops.abs(z - l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 20.995543660996834, 'samples': 79}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = absolute_error(z, loss)\n",
    "metric.test((X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `test` method tells us how many miles per gallon the model is off on average when predicting based on the test set we created earlier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
