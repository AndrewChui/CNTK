{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing hand-written digits\n",
    "This notebook demonstrates how to use a convolutional neural network for image recognition.\n",
    "We're using the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). \n",
    "\n",
    "You need a specially prepared dataset for this notebook. You can prepare the dataset for this notebook using the notebook \"Prepare the dataset.ipynb\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network structure\n",
    "The neural network has two convolution layers and two max-pooling layers mixed together.\n",
    "The output of the neural network is a softmax activated dense layer with 10 neurons. Each for one of the different labels that we can predict with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.layers import Convolution2D, Sequential, Dense, MaxPooling\n",
    "from cntk.ops import log_softmax, relu\n",
    "from cntk.initializer import glorot_uniform\n",
    "from cntk import input_variable, default_options\n",
    "\n",
    "features = input_variable((3,28,28))\n",
    "labels = input_variable(10)\n",
    "\n",
    "with default_options(initialization=glorot_uniform, activation=relu):\n",
    "    model = Sequential([\n",
    "        Convolution2D(filter_shape=(5,5), strides=(1,1), num_filters=8, pad=True),\n",
    "        MaxPooling(filter_shape=(2,2), strides=(2,2)),\n",
    "        Convolution2D(filter_shape=(5,5), strides=(1,1), num_filters=16, pad=True),\n",
    "        MaxPooling(filter_shape=(3,3), strides=(3,3)),\n",
    "        Dense(10, activation=log_softmax)\n",
    "    ])\n",
    "\n",
    "z = model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss for the model is a categorical cross entropy. We're using a `Function` object to combine the loss with a metric to measure the performance of the model. This `criterion_factory` is used to create the objective for the training logic. We're using a SGD learner for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk import Function\n",
    "from cntk.losses import cross_entropy_with_softmax\n",
    "from cntk.metrics import classification_error\n",
    "from cntk.learners import sgd\n",
    "\n",
    "@Function\n",
    "def criterion_factory(output, targets):\n",
    "    loss = cross_entropy_with_softmax(output, targets)\n",
    "    metric = classification_error(output, targets)\n",
    "    \n",
    "    return loss, metric\n",
    "\n",
    "loss = criterion_factory(z, labels)\n",
    "learner = sgd(z.parameters, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.learners import sgd\n",
    "\n",
    "loss = criterion_factory(z, labels)\n",
    "learner = sgd(z.parameters, lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data source\n",
    "The data is stored as images on disk with a mapping file that combines the filename of the images with the label for each of the images. We're using random transforms during training to augment the training data in an attempt to improve performance.\n",
    "\n",
    "Note that these transforms are not applied during testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cntk.io import MinibatchSource, StreamDef, StreamDefs, ImageDeserializer, INFINITELY_REPEAT\n",
    "import cntk.io.transforms as xforms\n",
    "\n",
    "def create_datasource(folder, train=True, max_sweeps=INFINITELY_REPEAT):\n",
    "    mapping_file = os.path.join(folder, 'mapping.bin')\n",
    "    \n",
    "    image_transforms = []\n",
    "    \n",
    "    if train:\n",
    "        image_transforms += [\n",
    "            xforms.crop(crop_type='randomside', side_ratio=0.8),\n",
    "            xforms.scale(width=28, height=28, channels=3, interpolations='linear')\n",
    "        ]\n",
    "        \n",
    "    stream_definitions = StreamDefs(\n",
    "        features=StreamDef(field='image', transforms=image_transforms),\n",
    "        labels=StreamDef(field='label', shape=10)\n",
    "    )\n",
    "    \n",
    "    deserializer = ImageDeserializer(mapping_file, stream_definitions)\n",
    "    \n",
    "    return MinibatchSource(deserializer, max_sweeps=max_sweeps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data and testing data is stored in separate folders.\n",
    "You need a separate data source for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasource = create_datasource('mnist_train')\n",
    "test_datasource = create_datasource('mnist_test', max_sweeps=1, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The model is trained for one epoch with a batchsize of 64. We've added the progress printer to visualize the output of the training session. We've also included the test set here to validate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.2\n",
      "      142        142      0.922      0.922            64\n",
      " 1.35e+06   2.03e+06      0.896      0.883           192\n",
      "  5.8e+05       2.25      0.895      0.895           448\n",
      " 2.71e+05       2.25      0.898        0.9           960\n",
      " 1.31e+05       2.25      0.892      0.887          1984\n",
      " 6.45e+04       2.25      0.891      0.891          4032\n",
      "  3.2e+04       2.25       0.89      0.889          8128\n",
      " 1.59e+04       2.25       0.89      0.889         16320\n",
      " 7.95e+03       2.25       0.89       0.89         32704\n",
      "      2.3        2.3      0.891      0.891            64\n",
      "      2.3        2.3      0.885      0.883           192\n",
      "      2.3       2.31        0.9       0.91           448\n",
      "      2.3        2.3      0.893      0.887           960\n",
      "      2.3        2.3      0.886       0.88          1984\n",
      "      2.3        2.3      0.885      0.883          4032\n",
      "      2.3        2.3      0.888      0.892          8128\n",
      "      2.3        2.3      0.888      0.887         16320\n",
      "      2.3        2.3      0.889      0.889         32704\n",
      "     2.29       2.29      0.828      0.828            64\n",
      "      2.3        2.3      0.859      0.875           192\n",
      "      2.3        2.3      0.875      0.887           448\n",
      "      2.3        2.3      0.886      0.896           960\n",
      "      2.3        2.3      0.883       0.88          1984\n",
      "      2.3        2.3      0.885      0.888          4032\n",
      "      2.3        2.3      0.885      0.884          8128\n",
      "      2.3        2.3      0.885      0.886         16320\n",
      "      2.3        2.3      0.889      0.892         32704\n",
      "     2.31       2.31      0.906      0.906            64\n",
      "      2.3        2.3       0.88      0.867           192\n",
      "      2.3        2.3      0.891      0.898           448\n",
      "      2.3        2.3      0.883      0.877           960\n",
      "      2.3        2.3      0.881      0.879          1984\n",
      "      2.3        2.3      0.882      0.884          4032\n",
      "      2.3        2.3      0.891        0.9          8128\n",
      "      2.3        2.3      0.892      0.893         16320\n",
      "      2.3        2.3      0.889      0.885         32704\n",
      "     2.29       2.29      0.812      0.812            64\n",
      "      2.3        2.3      0.865      0.891           192\n",
      "      2.3        2.3      0.888      0.906           448\n",
      "      2.3        2.3      0.901      0.912           960\n",
      "      2.3        2.3      0.888      0.875          1984\n",
      "      2.3        2.3      0.888      0.888          4032\n",
      "      2.3        2.3      0.889      0.891          8128\n",
      "      2.3        2.3      0.888      0.886         16320\n",
      "      2.3        2.3      0.889       0.89         32704\n",
      "      2.3        2.3      0.797      0.797            64\n",
      "      2.3       2.31      0.875      0.914           192\n",
      "      2.3        2.3      0.879      0.883           448\n",
      "      2.3        2.3      0.877      0.875           960\n",
      "      2.3        2.3      0.886      0.895          1984\n",
      "      2.3        2.3      0.887      0.888          4032\n",
      "      2.3        2.3      0.886      0.886          8128\n",
      "      2.3        2.3      0.886      0.886         16320\n",
      "      2.3        2.3      0.889      0.891         32704\n",
      "      2.3        2.3      0.906      0.906            64\n",
      "      2.3       2.31      0.911      0.914           192\n",
      "      2.3        2.3      0.891      0.875           448\n",
      "      2.3        2.3      0.886      0.883           960\n",
      "      2.3        2.3      0.889      0.891          1984\n",
      "      2.3        2.3      0.885      0.882          4032\n",
      "      2.3        2.3      0.883      0.882          8128\n",
      "      2.3        2.3      0.887       0.89         16320\n",
      "      2.3        2.3      0.887      0.887         32704\n",
      "     2.31       2.31      0.906      0.906            64\n",
      "      2.3        2.3      0.891      0.883           192\n",
      "      2.3       2.31      0.886      0.883           448\n",
      "      2.3        2.3      0.885      0.885           960\n",
      "      2.3        2.3      0.887      0.888          1984\n",
      "      2.3        2.3      0.888      0.889          4032\n",
      "      2.3        2.3      0.886      0.884          8128\n",
      "      2.3        2.3       0.89      0.894         16320\n",
      "      2.3        2.3      0.887      0.885         32704\n",
      "      2.3        2.3      0.828      0.828            64\n",
      "      2.3        2.3      0.875      0.898           192\n",
      "      2.3        2.3      0.893      0.906           448\n",
      "      2.3        2.3      0.898      0.902           960\n",
      "      2.3        2.3      0.892      0.886          1984\n",
      "      2.3        2.3       0.88      0.869          4032\n",
      "      2.3        2.3      0.883      0.885          8128\n",
      "      2.3        2.3      0.885      0.887         16320\n",
      "      2.3        2.3      0.888      0.891         32704\n",
      "     2.32       2.32      0.938      0.938            64\n",
      "     2.31        2.3      0.922      0.914           192\n",
      "     2.31        2.3      0.897      0.879           448\n",
      "     2.31       2.31      0.898      0.898           960\n",
      "      2.3        2.3      0.893      0.888          1984\n",
      "      2.3        2.3      0.893      0.893          4032\n",
      "      2.3        2.3      0.889      0.885          8128\n",
      "      2.3        2.3      0.891      0.893         16320\n",
      "      2.3        2.3       0.89       0.89         32704\n",
      "Finished Evaluation [1]: Minibatch[1-313]: metric = 88.65% * 10000;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'updates': [{'loss': 142.24903869628906, 'metric': 0.921875, 'samples': 64},\n",
       "  {'loss': 2031604.0004806519, 'metric': 0.8828125, 'samples': 128},\n",
       "  {'loss': 2.25, 'metric': 0.89453125, 'samples': 256},\n",
       "  {'loss': 2.25, 'metric': 0.900390625, 'samples': 512},\n",
       "  {'loss': 2.25, 'metric': 0.88671875, 'samples': 1024},\n",
       "  {'loss': 2.25, 'metric': 0.890625, 'samples': 2048},\n",
       "  {'loss': 2.25, 'metric': 0.88916015625, 'samples': 4096},\n",
       "  {'loss': 2.25, 'metric': 0.8887939453125, 'samples': 8192},\n",
       "  {'loss': 2.25, 'metric': 0.88958740234375, 'samples': 16384},\n",
       "  {'loss': 2.2993674278259277, 'metric': 0.890625, 'samples': 64},\n",
       "  {'loss': 2.3043177127838135, 'metric': 0.8828125, 'samples': 128},\n",
       "  {'loss': 2.3054208755493164, 'metric': 0.91015625, 'samples': 256},\n",
       "  {'loss': 2.298907995223999, 'metric': 0.88671875, 'samples': 512},\n",
       "  {'loss': 2.300419807434082, 'metric': 0.8798828125, 'samples': 1024},\n",
       "  {'loss': 2.3008246421813965, 'metric': 0.88330078125, 'samples': 2048},\n",
       "  {'loss': 2.3028628826141357, 'metric': 0.89208984375, 'samples': 4096},\n",
       "  {'loss': 2.301856517791748, 'metric': 0.88720703125, 'samples': 8192},\n",
       "  {'loss': 2.302037000656128, 'metric': 0.88934326171875, 'samples': 16384},\n",
       "  {'loss': 2.2924373149871826, 'metric': 0.828125, 'samples': 64},\n",
       "  {'loss': 2.3039437532424927, 'metric': 0.875, 'samples': 128},\n",
       "  {'loss': 2.3024356365203857, 'metric': 0.88671875, 'samples': 256},\n",
       "  {'loss': 2.3022143840789795, 'metric': 0.896484375, 'samples': 512},\n",
       "  {'loss': 2.3008158206939697, 'metric': 0.8798828125, 'samples': 1024},\n",
       "  {'loss': 2.3019275665283203, 'metric': 0.8876953125, 'samples': 2048},\n",
       "  {'loss': 2.3018696308135986, 'metric': 0.884033203125, 'samples': 4096},\n",
       "  {'loss': 2.301302194595337, 'metric': 0.8861083984375, 'samples': 8192},\n",
       "  {'loss': 2.3020551204681396, 'metric': 0.89166259765625, 'samples': 16384},\n",
       "  {'loss': 2.307121992111206, 'metric': 0.90625, 'samples': 64},\n",
       "  {'loss': 2.3007251024246216, 'metric': 0.8671875, 'samples': 128},\n",
       "  {'loss': 2.300445795059204, 'metric': 0.8984375, 'samples': 256},\n",
       "  {'loss': 2.299884796142578, 'metric': 0.876953125, 'samples': 512},\n",
       "  {'loss': 2.3004963397979736, 'metric': 0.87890625, 'samples': 1024},\n",
       "  {'loss': 2.30279803276062, 'metric': 0.8837890625, 'samples': 2048},\n",
       "  {'loss': 2.3019893169403076, 'metric': 0.900146484375, 'samples': 4096},\n",
       "  {'loss': 2.302518367767334, 'metric': 0.8931884765625, 'samples': 8192},\n",
       "  {'loss': 2.3019473552703857, 'metric': 0.88494873046875, 'samples': 16384},\n",
       "  {'loss': 2.293811559677124, 'metric': 0.8125, 'samples': 64},\n",
       "  {'loss': 2.303554654121399, 'metric': 0.890625, 'samples': 128},\n",
       "  {'loss': 2.3005943298339844, 'metric': 0.90625, 'samples': 256},\n",
       "  {'loss': 2.3045248985290527, 'metric': 0.912109375, 'samples': 512},\n",
       "  {'loss': 2.3027138710021973, 'metric': 0.875, 'samples': 1024},\n",
       "  {'loss': 2.3016581535339355, 'metric': 0.88818359375, 'samples': 2048},\n",
       "  {'loss': 2.3025126457214355, 'metric': 0.890869140625, 'samples': 4096},\n",
       "  {'loss': 2.3016715049743652, 'metric': 0.8858642578125, 'samples': 8192},\n",
       "  {'loss': 2.302415370941162, 'metric': 0.89019775390625, 'samples': 16384},\n",
       "  {'loss': 2.2961020469665527, 'metric': 0.796875, 'samples': 64},\n",
       "  {'loss': 2.307734251022339, 'metric': 0.9140625, 'samples': 128},\n",
       "  {'loss': 2.302955389022827, 'metric': 0.8828125, 'samples': 256},\n",
       "  {'loss': 2.300699472427368, 'metric': 0.875, 'samples': 512},\n",
       "  {'loss': 2.3036859035491943, 'metric': 0.89453125, 'samples': 1024},\n",
       "  {'loss': 2.303048849105835, 'metric': 0.88818359375, 'samples': 2048},\n",
       "  {'loss': 2.300229787826538, 'metric': 0.8857421875, 'samples': 4096},\n",
       "  {'loss': 2.302762985229492, 'metric': 0.886474609375, 'samples': 8192},\n",
       "  {'loss': 2.302246332168579, 'metric': 0.8907470703125, 'samples': 16384},\n",
       "  {'loss': 2.3041391372680664, 'metric': 0.90625, 'samples': 64},\n",
       "  {'loss': 2.305260181427002, 'metric': 0.9140625, 'samples': 128},\n",
       "  {'loss': 2.2995266914367676, 'metric': 0.875, 'samples': 256},\n",
       "  {'loss': 2.3026809692382812, 'metric': 0.8828125, 'samples': 512},\n",
       "  {'loss': 2.304450750350952, 'metric': 0.890625, 'samples': 1024},\n",
       "  {'loss': 2.301201343536377, 'metric': 0.88232421875, 'samples': 2048},\n",
       "  {'loss': 2.3001534938812256, 'metric': 0.881591796875, 'samples': 4096},\n",
       "  {'loss': 2.3016345500946045, 'metric': 0.890380859375, 'samples': 8192},\n",
       "  {'loss': 2.3017373085021973, 'metric': 0.8873291015625, 'samples': 16384},\n",
       "  {'loss': 2.3094916343688965, 'metric': 0.90625, 'samples': 64},\n",
       "  {'loss': 2.3007009029388428, 'metric': 0.8828125, 'samples': 128},\n",
       "  {'loss': 2.305218458175659, 'metric': 0.8828125, 'samples': 256},\n",
       "  {'loss': 2.3019676208496094, 'metric': 0.884765625, 'samples': 512},\n",
       "  {'loss': 2.302243232727051, 'metric': 0.8876953125, 'samples': 1024},\n",
       "  {'loss': 2.3024885654449463, 'metric': 0.888671875, 'samples': 2048},\n",
       "  {'loss': 2.3011395931243896, 'metric': 0.8837890625, 'samples': 4096},\n",
       "  {'loss': 2.302866220474243, 'metric': 0.8944091796875, 'samples': 8192},\n",
       "  {'loss': 2.301051378250122, 'metric': 0.884521484375, 'samples': 16384},\n",
       "  {'loss': 2.300192356109619, 'metric': 0.828125, 'samples': 64},\n",
       "  {'loss': 2.303616762161255, 'metric': 0.8984375, 'samples': 128},\n",
       "  {'loss': 2.2979342937469482, 'metric': 0.90625, 'samples': 256},\n",
       "  {'loss': 2.298112392425537, 'metric': 0.90234375, 'samples': 512},\n",
       "  {'loss': 2.303710460662842, 'metric': 0.8857421875, 'samples': 1024},\n",
       "  {'loss': 2.2988648414611816, 'metric': 0.869140625, 'samples': 2048},\n",
       "  {'loss': 2.3025031089782715, 'metric': 0.88525390625, 'samples': 4096},\n",
       "  {'loss': 2.300992727279663, 'metric': 0.88671875, 'samples': 8192},\n",
       "  {'loss': 2.302164316177368, 'metric': 0.89117431640625, 'samples': 16384},\n",
       "  {'loss': 2.3217084407806396, 'metric': 0.9375, 'samples': 64},\n",
       "  {'loss': 2.3018189668655396, 'metric': 0.9140625, 'samples': 128},\n",
       "  {'loss': 2.3024744987487793, 'metric': 0.87890625, 'samples': 256},\n",
       "  {'loss': 2.3050639629364014, 'metric': 0.8984375, 'samples': 512},\n",
       "  {'loss': 2.3028547763824463, 'metric': 0.8876953125, 'samples': 1024},\n",
       "  {'loss': 2.3039770126342773, 'metric': 0.89306640625, 'samples': 2048},\n",
       "  {'loss': 2.3014800548553467, 'metric': 0.884765625, 'samples': 4096},\n",
       "  {'loss': 2.3016557693481445, 'metric': 0.892578125, 'samples': 8192},\n",
       "  {'loss': 2.302459955215454, 'metric': 0.88983154296875, 'samples': 16384}],\n",
       " 'epoch_summaries': [{'loss': 4334.172707889125,\n",
       "   'metric': 0.8895589019189766,\n",
       "   'samples': 60032},\n",
       "  {'loss': 2.3019399408851386, 'metric': 0.8890241462113126, 'samples': 59968},\n",
       "  {'loss': 2.301931157549307, 'metric': 0.8891924307036247, 'samples': 60032},\n",
       "  {'loss': 2.301841971968383, 'metric': 0.8892409284951974, 'samples': 59968},\n",
       "  {'loss': 2.3018827458688698, 'metric': 0.8885927505330491, 'samples': 60032},\n",
       "  {'loss': 2.301926391992396, 'metric': 0.8888573906083245, 'samples': 59968},\n",
       "  {'loss': 2.3019277739372335, 'metric': 0.888842617270789, 'samples': 60032},\n",
       "  {'loss': 2.3020222764641143, 'metric': 0.8888740661686233, 'samples': 59968},\n",
       "  {'loss': 2.3019582264458953, 'metric': 0.8889925373134329, 'samples': 60032},\n",
       "  {'loss': 2.30194671533151, 'metric': 0.8887573372465315, 'samples': 59968}],\n",
       " 'test_summary': {'metric': 0.8865, 'samples': 10000}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.train import TestConfig\n",
    "\n",
    "\n",
    "progress_writer = ProgressPrinter(0)\n",
    "\n",
    "test_config = TestConfig(test_datasource)\n",
    "\n",
    "input_map = {\n",
    "    features: train_datasource.streams.features,\n",
    "    labels: train_datasource.streams.labels\n",
    "}\n",
    "\n",
    "loss.train(train_datasource, \n",
    "           max_epochs=10,\n",
    "           minibatch_size=64,\n",
    "           epoch_size=60000, \n",
    "           parameter_learners=[learner], \n",
    "           model_inputs_to_streams=input_map,  \n",
    "           callbacks=[progress_writer, test_config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
