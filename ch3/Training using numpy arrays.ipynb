{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using numpy arrays\n",
    "In this notebook we'll take a look at how to use numpy data to train a neural network in CNTK.\n",
    "The model used here is a basic classification model that uses random training samples. The goal is to demonstrate how to use numpy, so we left out the stuff that you don't need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the random seed\n",
    "The sample relies on random numbers. In order to keep the results predictable we'll set the random seed for the random number generators to a fixed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk\n",
    "import numpy \n",
    "\n",
    "cntk._cntk_py.set_fixed_random_seed(1337)\n",
    "numpy.random.seed = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sample data\n",
    "Before we can actually train the model, we need to generate some sample data. We need a set of input features and a set of labels for our model. \n",
    "\n",
    "The labels are stored as one-hot vectors. To generate them we first create an identity matrix that has the same size as the number of classes that we want to predict. We can now use the `random.choice` function to select an index value at random. You can repeat this random selection process a number of times by specifying this as the second argument of the function. We feed the randomly selected indices to the indexer of the identity matrix. This will select random rows from the identity matrix 20.000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 20000\n",
    "\n",
    "y = np.eye(2)[np.random.choice(2,num_samples)].astype(np.float32)\n",
    "X = np.random.random(size=(num_samples, 4)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "The model is a basic classification model. We use one hidden layer and an output layer. \n",
    "Both have a sigmoid activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.layers import Dense, Sequential\n",
    "from cntk import input_variable, default_options\n",
    "from cntk.ops import sigmoid\n",
    "\n",
    "with default_options(activation=sigmoid):\n",
    "    model = Sequential([\n",
    "        Dense(4),\n",
    "        Dense(2)\n",
    "    ])\n",
    "\n",
    "features = input_variable(4)\n",
    "\n",
    "z = model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network\n",
    "To train the neural network you can invoke the `train` method on the loss function to feed the numpy data in chunks. These chunks are called minibatches. \n",
    "\n",
    "We've attached a progress printer to the training process so you can see what's going on.\n",
    "Also note, that we used a `minibatch_size` setting to control the number of samples per minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.5\n",
      "      1.4        1.4          0          0           512\n",
      "      1.4       1.39          0          0          1536\n",
      "     1.39       1.39          0          0          3584\n",
      "     1.39       1.39          0          0          7680\n",
      "     1.39       1.39          0          0         15872\n"
     ]
    }
   ],
   "source": [
    "from cntk.learners import sgd\n",
    "from cntk.losses import binary_cross_entropy\n",
    "from cntk.logging import ProgressPrinter\n",
    "\n",
    "progress_writer = ProgressPrinter(0)\n",
    "\n",
    "labels = input_variable(2)\n",
    "learner = sgd(z.parameters, lr=0.5)\n",
    "loss = binary_cross_entropy(z, labels)\n",
    "\n",
    "training_summary = loss.train((X,y), \n",
    "  parameter_learners=[learner], \n",
    "  callbacks=[progress_writer], \n",
    "  minibatch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
