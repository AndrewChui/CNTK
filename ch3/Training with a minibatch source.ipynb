{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with a minibatch source\n",
    "This notebook demonstrates how to use minibatch sources in CNTK to work with datasets that don't fit in memory fully.\n",
    "We'll work on a basic classification model just like in the other notebooks for this chapter. Except this time we're using a minibatch source to train the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the minibatch source\n",
    "In order to train the model we'll create a minibatch source. The minibatch source in CNTK needs a deserializer that can read the input data. We're using a CTF deserializer here as we're reading a CTF file. The CTF file contains two streams: features and labels. We'll have to define separate stream sources for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.io import StreamDef, StreamDefs, MinibatchSource, CTFDeserializer, INFINITELY_REPEAT\n",
    "\n",
    "labels_stream = StreamDef(field='labels', shape=3, is_sparse=False)\n",
    "features_stream = StreamDef(field='features', shape=4, is_sparse=False)\n",
    "\n",
    "deserializer = CTFDeserializer('iris.ctf', StreamDefs(labels=labels_stream, features=features_stream))\n",
    "\n",
    "minibatch_source = MinibatchSource(deserializer, randomize=True, max_sweeps=INFINITELY_REPEAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "The model is a basic classification model. We use one hidden layer and an output layer. \n",
    "Both have a sigmoid activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk import default_options, input_variable\n",
    "from cntk.layers import Dense, Sequential\n",
    "from cntk.ops import log_softmax, relu, sigmoid\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(4, activation=sigmoid),\n",
    "    Dense(3, activation=log_softmax)\n",
    "])\n",
    "\n",
    "features = input_variable(4)\n",
    "labels = input_variable(3)\n",
    "\n",
    "z = model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss for this model is a cross-entropy loss function. We're using a SGD learner to optimize the parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.losses import cross_entropy_with_softmax\n",
    "from cntk.learners import sgd \n",
    "\n",
    "loss = cross_entropy_with_softmax(z, labels)\n",
    "learner = sgd(z.parameters, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Now that we have a minibatch source we can setup a training session and a trainer. The trainer uses the loss and learner to train the model. The training session is configured to read training data from our minibatch source and feeds the data into the trainer to optimize the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.1\n",
      "     1.53       1.53          0          0            16\n",
      "     1.27       1.14          0          0            48\n",
      "     1.23       1.21          0          0           112\n",
      "     1.15       1.08          0          0           240\n",
      "      1.1       1.04          0          0           496\n",
      "     1.02      0.953          0          0          1008\n",
      "    0.913      0.805          0          0          2032\n",
      "    0.736      0.559          0          0          4080\n"
     ]
    }
   ],
   "source": [
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.train import Trainer, training_session\n",
    "\n",
    "minibatch_size = 16\n",
    "samples_per_epoch = 150\n",
    "num_epochs = 30\n",
    "max_samples = samples_per_epoch * num_epochs\n",
    "\n",
    "input_map = {\n",
    "    features: minibatch_source.streams.features,\n",
    "    labels: minibatch_source.streams.labels\n",
    "}\n",
    "\n",
    "progress_writer = ProgressPrinter(0)\n",
    "trainer = Trainer(z, (loss, None), learner, progress_writer)\n",
    "\n",
    "session = training_session(trainer, \n",
    "                           mb_source=minibatch_source,\n",
    "                           mb_size=minibatch_size, \n",
    "                           model_inputs_to_streams=input_map, \n",
    "                           max_samples=max_samples)\n",
    "\n",
    "session.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
