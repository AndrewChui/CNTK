{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run an experiment on Azure Machine Learning Service\n",
    "This notebook demonstrates how to train a model using Azure Machine Learning Service.\n",
    "We will be working on a model that can predict which species an iris flower is based on the size of different parts of the flower. This notebook is based on the open source [iris flower dataset](https://archive.ics.uci.edu/ml/datasets/Iris)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "In this step we're going to define a model that we want to train.\n",
    "The input for the model is a vector with four features specifying the properties of each iris flower:\n",
    " \n",
    " - Sepal length\n",
    " - Sepal width\n",
    " - Petal length\n",
    " - Petal width\n",
    " \n",
    "In order for the model to work we need to define its input as an `input_variable`. This variable should have the same size as the number of features that we want to use for making a prediction. In this case it should be 4, because we have 4 different features in our dataset.\n",
    "\n",
    "The output layer of the model has three neurons, one for each species of flowers that we can predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk import default_options, input_variable\n",
    "from cntk.layers import Dense, Sequential\n",
    "from cntk.ops import log_softmax, sigmoid\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(4, activation=sigmoid),\n",
    "    Dense(3, activation=log_softmax)\n",
    "])\n",
    "\n",
    "features = input_variable(4)\n",
    "z = model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and record it in the workspace\n",
    "After we've created the model we can train it. We'll train the model and track it using the tracking logic provided by the Azure Machine Learning Environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Before we can actually train the model, we need to load the data from disk. We will use pandas for this.\n",
    "Pandas is widely used python library for working with data. It contains functions to load and process data \n",
    "as well as a large amount functions to perform statistical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_source = pd.read_csv('iris.csv', \n",
    "    names=['sepal_length', 'sepal_width','petal_length','petal_width', 'species'], \n",
    "    index_col=False)\n",
    "\n",
    "X = df_source.iloc[:, :4].values\n",
    "y = df_source['species'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model doesn't take strings as values. It needs floating point values to do its job. So we need to encode the strings into a floating point representation. We can do this by mapping the species names to a one-hot encoded version of the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'Iris-setosa': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-virginica': 2\n",
    "}\n",
    "\n",
    "def one_hot(index, length):\n",
    "    result = np.zeros(length)\n",
    "    result[index] = 1.\n",
    "    \n",
    "    return result\n",
    "    \n",
    "y = [one_hot(label_mapping[v], 3) for v in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNTK is configured to use 32-bit floats by default. Right the features are stored as 64-bit floats and the labels are stored as integers. In order to help CNTK make sense of this, we will have to convert our data to 32-bit floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the challenges with machine learning is the fact that your model will try to memorize every bit of data it saw. This is called overfitting and bad for your model as it is no longer able to correctly predict outcome correctly for samples it didn't see before. We want our model to learn a set of rules that predict the correct class of flower. \n",
    "\n",
    "In order for us to detect overfitting we need to split the dataset into a training and test set. This is done using a utility function found in the scikit-learn python package which is included with your standard anaconda installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the target and loss\n",
    "Let's define a target for our model and a loss function. The loss function measures the distance between the actual and predicted value. The loss is later used by the learner to optimize the parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.losses import cross_entropy_with_softmax\n",
    "from cntk.metrics import classification_error\n",
    "from cntk.learners import sgd\n",
    "from cntk.train.trainer import Trainer\n",
    "\n",
    "label = input_variable(3)\n",
    "\n",
    "loss = cross_entropy_with_softmax(z, label)\n",
    "error_rate = classification_error(z, label)\n",
    "\n",
    "learner = sgd(z.parameters, 0.001)\n",
    "trainer = Trainer(z, (loss, error_rate), [learner])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "We can train the model as normal. In order to track information about the model we need to setup a workspace and experiment in the Azure Machine Learning workspace that we've configured in the `config.json` in the same folder as this notebook. Please refer to chapter 7, Deploying models to production, to learn more on how to create this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: D:\\projects\\cntk-book\\ch7\\azure-ml-service\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "experiment = Experiment(name='classify-flowers', workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start tracking methods by calling the `start_logging` method on the experiment. This starts a new run instance that has all the tracking logic that we need for our experiment. We can use `log` to track metrics. We can also use `upload_file` to store outputs generated by our run. And finally we can register uploaded files as models in the model registry so we can deploy them to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input246\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n",
      "c:\\anaconda3\\lib\\site-packages\\cntk\\core.py:411: UserWarning: you provided the minibatch data as a list, but your corresponding input variable (uid \"Input395\") has only one dynamic axis (batch axis). To speed up graph execution, please convert the data beforehand into one NumPy array to speed up training.\n",
      "  'training.' % var.uid)\n",
      "c:\\anaconda3\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input395\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from cntk import ModelFormat\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "with experiment.start_logging() as run:\n",
    "    for _ in range(10):\n",
    "        trainer.train_minibatch({ features: X_train, label: y_train })\n",
    "\n",
    "        run.log('average_loss', trainer.previous_minibatch_loss_average)\n",
    "        run.log('average_metric', trainer.previous_minibatch_evaluation_average)\n",
    "        \n",
    "    test_metric = trainer.test_minibatch( {features: X_test, label: y_test })\n",
    "    \n",
    "    run.log('test_metric', test_metric)\n",
    "    \n",
    "    z.save('outputs/model.onnx', ModelFormat.ONNX)\n",
    "    run.upload_file('model.onnx', 'outputs/model.onnx')\n",
    "    \n",
    "    stored_model = run.register_model(model_name='classify_flowers', model_path='model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model to production\n",
    "Now that we have a trained model we can deploy it to production. We need to setup an image for this and a deploy the image as a webservice to the cloud. Let's start with the image first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(\n",
    "    execution_script=\"score.py\", \n",
    "    runtime=\"python\", \n",
    "    conda_file=\"conda_env.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the configuration for the image we can invoke deploy_from_model with a deployment configuration to deploy the model as a Azure container instance to the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image classify-flowers-svc-1:1, operation \"Succeeded\"\n",
      "Creating service\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name='classify-flowers-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[stored_model],\n",
    "                                       image_config=image_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
