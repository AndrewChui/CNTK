{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training recurrent neural networks\n",
    "This notebook contains the sample code to train a recurrent neural networks to predict the total power output for a day of a solar panel. The dataset is preprocessed and available with this notebook. You can however regenerate the dataset using the notebook \"Prepare the dataset.ipynb\" which is in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.losses import squared_error\n",
    "from cntk.io import CTFDeserializer, MinibatchSource, INFINITELY_REPEAT, StreamDefs, StreamDef\n",
    "from cntk.learners import adam\n",
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.train import TestConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook uses a set of constants to control various settings.\n",
    "The most important settings are the batch size, epoch size and number of epochs to train for.\n",
    "\n",
    "We've normalized the training data based on the maximum total power generated by the solar panel. \n",
    "This value is stored as a constant here to denormalize the output of the neural network normal usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 14 * 10\n",
    "EPOCH_SIZE = 12434\n",
    "EPOCHS = 10\n",
    "\n",
    "# This value is required to convert the normalized values back to their original value.\n",
    "# You can obtain this value by looking at the maximum value for the solar.total column\n",
    "NORMALIZE = 19100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "The model we're using is a recurrent neural network with an LSTM as the implementation for the recurrent layer in the network. We've wrapped the LSTM in a Fold layer because we're only interested in the final output of the recurrent layer. \n",
    "The output of the network is generated using a final Dense layer.\n",
    "\n",
    "Note, the input features for the model are stored in a sequence input variable. This is required since we're working with sequences rather than single samples. The target output is stored in a regular input variable as we're only interested in predicting a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk import sequence, default_options, input_variable\n",
    "from cntk.layers import Recurrence, LSTM, Dropout, Dense, Sequential, Fold\n",
    "features = sequence.input_variable(1)\n",
    "\n",
    "with default_options(initial_state = 0.1):\n",
    "    model = Sequential([\n",
    "        Fold(LSTM(15)),\n",
    "        Dense(1)\n",
    "    ])(features)\n",
    "    \n",
    "target = input_variable(1, dynamic_axes=model.dynamic_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The model is trained using a mean squared error loss function. The data for the model is coming from a set of CTF Files containing sequences of measurements per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk import Function\n",
    "\n",
    "@Function\n",
    "def criterion_factory(z, t):\n",
    "    loss = squared_error(z, t)\n",
    "    metric = squared_error(z, t)    \n",
    "    \n",
    "    return loss, metric\n",
    "\n",
    "loss = criterion_factory(model, target)\n",
    "learner = adam(model.parameters, lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load data into the training process we need to deserialize sequences from a set of CTF files. The `create_datasource` function is a useful utility function to create both the training and test datasources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasource(filename, sweeps=INFINITELY_REPEAT):\n",
    "    target_stream = StreamDef(field='target', shape=1, is_sparse=False)\n",
    "    features_stream = StreamDef(field='features', shape=1, is_sparse=False)\n",
    "\n",
    "    deserializer = CTFDeserializer(filename, StreamDefs(features=features_stream, target=target_stream))\n",
    "    datasource = MinibatchSource(deserializer, randomize=True, max_sweeps=sweeps)    \n",
    "    \n",
    "    return datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasource = create_datasource('solar_train.ctf')\n",
    "test_datasource = create_datasource('solar_val.ctf', sweeps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've setup the data sources, model, and loss function let's start the training process.\n",
    "Please be aware, this takes a long time on a computer with just a CPU. If you can, use a GPU to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.005\n",
      "      0.4        0.4        0.4        0.4            19\n",
      "      0.4        0.4        0.4        0.4            59\n",
      "    0.452      0.495      0.452      0.495           129\n",
      "     0.43      0.411       0.43      0.411           275\n",
      "    0.394      0.362      0.394      0.362           580\n",
      "    0.354      0.314      0.354      0.314          1150\n",
      "    0.281      0.207      0.281      0.207          2298\n",
      "    0.164     0.0495      0.164     0.0495          4643\n",
      "   0.0934     0.0235     0.0934     0.0235          9328\n",
      "   0.0141     0.0141     0.0141     0.0141            20\n",
      "   0.0229     0.0285     0.0229     0.0285            52\n",
      "   0.0219     0.0212     0.0219     0.0212           122\n",
      "   0.0209     0.0201     0.0209     0.0201           268\n",
      "    0.021      0.021      0.021      0.021           552\n",
      "   0.0187     0.0166     0.0187     0.0166          1132\n",
      "   0.0185     0.0183     0.0185     0.0183          2284\n",
      "   0.0182      0.018     0.0182      0.018          4626\n",
      "   0.0175     0.0167     0.0175     0.0167          9320\n",
      "   0.0114     0.0114     0.0114     0.0114            21\n",
      "   0.0129     0.0139     0.0129     0.0139            56\n",
      "   0.0142     0.0152     0.0142     0.0152           131\n",
      "   0.0146     0.0149     0.0146     0.0149           286\n",
      "   0.0154     0.0161     0.0154     0.0161           587\n",
      "   0.0147     0.0141     0.0147     0.0141          1153\n",
      "   0.0135     0.0123     0.0135     0.0123          2310\n",
      "   0.0131     0.0128     0.0131     0.0128          4631\n",
      "   0.0125     0.0119     0.0125     0.0119          9294\n",
      "  0.00751    0.00751    0.00751    0.00751            22\n",
      "  0.00843    0.00894    0.00843    0.00894            62\n",
      "   0.0103     0.0117     0.0103     0.0117           139\n",
      "   0.0121     0.0137     0.0121     0.0137           295\n",
      "   0.0117     0.0113     0.0117     0.0113           576\n",
      "   0.0112     0.0106     0.0112     0.0106          1169\n",
      "   0.0109     0.0106     0.0109     0.0106          2329\n",
      "   0.0107     0.0105     0.0107     0.0105          4670\n",
      "   0.0105     0.0104     0.0105     0.0104          9340\n",
      "  0.00534    0.00534    0.00534    0.00534            18\n",
      "  0.00759    0.00871    0.00759    0.00871            54\n",
      "  0.00754    0.00751    0.00754    0.00751           132\n",
      "  0.00931     0.0109    0.00931     0.0109           278\n",
      "  0.00994     0.0105    0.00994     0.0105           563\n",
      "  0.00981    0.00968    0.00981    0.00968          1150\n",
      "   0.0102     0.0105     0.0102     0.0105          2333\n",
      "  0.00973     0.0093    0.00973     0.0093          4679\n",
      "  0.00988       0.01    0.00988       0.01          9395\n",
      "   0.0179     0.0179     0.0179     0.0179            18\n",
      "   0.0115    0.00815     0.0115    0.00815            52\n",
      "   0.0117     0.0118     0.0117     0.0118           131\n",
      "  0.00987    0.00807    0.00987    0.00807           264\n",
      "  0.00957     0.0093    0.00957     0.0093           568\n",
      "  0.00991     0.0103    0.00991     0.0103          1125\n",
      "  0.00967    0.00944    0.00967    0.00944          2303\n",
      "  0.00974     0.0098    0.00974     0.0098          4653\n",
      "  0.00968    0.00963    0.00968    0.00963          9343\n",
      "  0.00789    0.00789    0.00789    0.00789            21\n",
      "  0.00592    0.00469    0.00592    0.00469            55\n",
      "  0.00902     0.0114    0.00902     0.0114           128\n",
      "   0.0101      0.011     0.0101      0.011           284\n",
      "  0.00997    0.00981    0.00997    0.00981           574\n",
      "  0.00925    0.00857    0.00925    0.00857          1173\n",
      "  0.00962    0.00998    0.00962    0.00998          2354\n",
      "   0.0095    0.00937     0.0095    0.00937          4688\n",
      "  0.00951    0.00952    0.00951    0.00952          9321\n",
      "  0.00865    0.00865    0.00865    0.00865            19\n",
      "  0.00779    0.00732    0.00779    0.00732            54\n",
      "  0.00966     0.0111    0.00966     0.0111           125\n",
      "  0.00876    0.00792    0.00876    0.00792           258\n",
      "  0.00892    0.00905    0.00892    0.00905           538\n",
      "  0.00898    0.00903    0.00898    0.00903          1123\n",
      "  0.00891    0.00885    0.00891    0.00885          2294\n",
      "  0.00936     0.0098    0.00936     0.0098          4651\n",
      "  0.00916    0.00896    0.00916    0.00896          9337\n",
      "  0.00773    0.00773    0.00773    0.00773            20\n",
      "  0.00928     0.0102    0.00928     0.0102            55\n",
      "  0.00985     0.0103    0.00985     0.0103           130\n",
      "  0.00996     0.0101    0.00996     0.0101           263\n",
      "   0.0102     0.0103     0.0102     0.0103           561\n",
      "  0.00905    0.00801    0.00905    0.00801          1159\n",
      "  0.00881    0.00856    0.00881    0.00856          2327\n",
      "  0.00893    0.00906    0.00893    0.00906          4642\n",
      "  0.00918    0.00942    0.00918    0.00942          9313\n",
      "  0.00653    0.00653    0.00653    0.00653            17\n",
      "  0.00789    0.00848    0.00789    0.00848            56\n",
      "  0.00916     0.0101    0.00916     0.0101           132\n",
      "  0.00899    0.00885    0.00899    0.00885           285\n",
      "  0.00975     0.0105    0.00975     0.0105           581\n",
      "  0.00938    0.00901    0.00938    0.00901          1176\n",
      "  0.00908    0.00879    0.00908    0.00879          2338\n",
      "   0.0089    0.00872     0.0089    0.00872          4697\n",
      "  0.00892    0.00894    0.00892    0.00894          9381\n",
      "Finished Evaluation [1]: Minibatch[1-598]: metric = 0.86% * 2239;\n"
     ]
    }
   ],
   "source": [
    "progress_writer = ProgressPrinter(0)\n",
    "test_config = TestConfig(test_datasource)\n",
    "\n",
    "input_map = {\n",
    "    features: train_datasource.streams.features,\n",
    "    target: train_datasource.streams.target\n",
    "}\n",
    "\n",
    "history = loss.train(\n",
    "    train_datasource, \n",
    "    epoch_size=EPOCH_SIZE,\n",
    "    parameter_learners=[learner], \n",
    "    model_inputs_to_streams=input_map,\n",
    "    callbacks=[progress_writer, test_config],\n",
    "    minibatch_size=BATCH_SIZE,\n",
    "    max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "You can use any CNTK model as a function, that's how we make our predictions in this notebook too. The model function accepts a numpy array as input. The shape of the array is defined as `<batch>x<timesteps>x<features>`. We're using a number of samples stored as a pickle file which we load and then feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input3\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8081.7905],\n",
       "       [16597.693 ],\n",
       "       [13335.17  ],\n",
       "       ...,\n",
       "       [11275.804 ],\n",
       "       [15621.697 ],\n",
       "       [16875.555 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('test_samples.pkl', 'rb') as test_file:\n",
    "    test_samples = pickle.load(test_file)\n",
    "    \n",
    "model(test_samples) * NORMALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
